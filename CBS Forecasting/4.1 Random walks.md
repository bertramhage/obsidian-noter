---
Dato: 21/10/2024
Slides: "[[4.1 Random walks]]"
---
An AR(1) model
$$
y_t = \beta y_{t-1}+\epsilon_t, \epsilon_t\sim WN(0,\sigma^2)
$$
with $\beta_1$ is a random walk or unit root process
$$
y_t = y_{t-1}+\epsilon_t=y_{0}+\sum_{i=1}^{t} \epsilon_{i} \, 
$$
Unlike the stationary processes with deterministic trend, random walk does not have a particular level to which it returns. If a shock lowers the value of a random walk, we expect it to stay permanently lower.

For a unit root model
$$
E(y_t) = E(y_0)+tE(\epsilon)=E(y_0)
$$
and
$$
var(y_t) = var(y_0)+tvar(\epsilon)=t\sigma^2
$$
## Drift
A unit root model with a drift is
$$
y_t = \delta+y_{t-1}+\epsilon_t
$$
$$
y_t = t\delta+y_0+\sum_{i=1}^{t} \epsilon_i \, 
$$
**Expected value and variance**
$$
E(y_t) = t\delta+E(y_0)+tE(\epsilon)=t\delta+E(y_0)
$$
and
$$
var(y_t) = var(t\delta)+var(y_0)+tvar(\epsilon)=t\sigma^2
$$
## ACF and PACF
ecognizing Random Walk: ACF and PACF If a series is random walk, its autocorrelation function is not well defined because its variance is infinite. But the sample autocorrelation function can still be mechanically computed in the usual way. One evidence on the random walk is that the sample ACF will tend to damp extremely slow, or fail to damp at all. In contrast, the sample PACF on random walk process will damp quickly: it will be close to 1 at lag 1, but will be small quickly thereafter.

**First differences**
First differences of random walk produce a white noise
$$
y_t = y_{t-1}=\Delta=\epsilon_t
$$
![[Pasted image 20241021085315.png]]
![[Pasted image 20241021085331.png]]

## Test for unit root
We want to test for 
$$
y_t = \left. \beta y_{t-1}+\epsilon_t \right| \beta=1
$$
Rewrite
$$
\Delta y_t = \varphi y_{t-1}+\epsilon_t
$$
where $\varphi=\beta-1$ and test the null hypothesis that $\varphi=0$.

The test statistic follows the Dickey-Fuller Distribution (not the normal t-distribution).
## ARIMA
We use ARIMA(p,d,q) models for estimation of random walk processes. ARIMA stands for **AutoRegressive Integrated Moving Average** model.

Due to increasing variance the uncertainty associated with our forecasts increases without a bound as the forecast horizon grows. We can make ARIMA(p,1,q) process stationary by taking first differences.

The forecast error variance is the sum of $h$ error variances, $h\sigma^{2}$
An $h$-step ahead 95% interval forecast for any future horizon is
$$
y_T \pm1.96\sqrt{ h\sigma^{2} }=y_T\pm1.96\sigma \sqrt{ h }
$$

