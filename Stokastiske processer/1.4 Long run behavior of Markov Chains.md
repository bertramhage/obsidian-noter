---
Dato: 17/9/2024
Slides: "[[week3.pdf]]"
Teaching Notes: "[[lesson3.pdf]]"
Pensum: 4.1,(4.2),4.3,4.4,(4.5)
---
## Regular Markov Chain
A markov chain on a finite number of states $N$ is **regular** if 
$$
\exists k(P^k_{ij}>0, \forall i,j\in [0,N]).
$$
Furthermore
$$
P \text{ on $N$ states: regular} \implies P^{N^2}_{ij}>0, \forall i,j \in[0,N]
$$
$$
\exists i,j\in[0,N](P^{N^2}_{ij}=0)\implies \text{not regular}
$$
$$
P^{k}_{ij}>0, \forall i,j\in[0,N]\implies P^{k+n}_{ij}>0, \forall i,j\in[0,N], \forall n\in\mathbb{N}
$$
>[!info] Theorem 4.1
>Let P be a regular transition probability matrix on the states $0,1,\dots ,N$. Then the limiting distribution $\mathbf{\pi}=(\pi_0, \pi_1, \dots, \pi_N)$ is the unique nonnegative solution of the equations
>$$
>\pi_j=\sum_{k=0}^{N} \pi_kP_{kj} \, ,j=0,1,\dots,N,
>$$
>$$
>\sum_{k=0}^{N} \pi_k \, =1.
>$$

#### Double stochastic matrix
A transition probability matrix is called **double stochastic** if
$$
\sum_kP_{ik}=\sum_kP_{kj}=1, \, \forall i,j, \text{ i.e. all row and columns sum to 1.}
$$
## Classification of states
+ $i$ is **transient** if $\sum_{n=1}^{\infty} P^{(n)}_{ii}<1 \,$
+ $i$ is **recurrent** if and only if $\sum_{n=1}^{\infty} P_{ii}^{(n)}=\infty \,$
	+ $i\leftrightarrow j\land i\text{ is recurrent}\implies j\text{ is recurrent}$
+ $i$ is **absorbing** if $P_{ii}=1$
+ $j$ is **accessible** from $i$ if $\exists n≥0(P^{(n)}_{ij}>0)$
+ $i$ and $j$ are **communicative**, $i\leftrightarrow j$, if they are each accessible to the other
	+ $i\leftrightarrow i$
	+ $i\leftrightarrow j\implies j\leftrightarrow i$
	+ $i\leftrightarrow j\land j\leftrightarrow k\implies i\leftrightarrow k$

#### Classes
A collection of states that communicates together. It's possible to enter another class but then it is not possible to return to the initial class (otherwise it would be the same class).

A markov chain is **irreducible** when it contains only one class.

## Periodicity
The **period** of state $i$, $d(i)$ is the g.c.d. of $n\in\mathbb{N}$ where $P^{(n)}_{ii}>0$.
If $P^{(n)}_{ii}=0, \forall n\in\mathbb{N}$ define $d(i)=0$.

+ $i\leftrightarrow j\implies d(i)=d(j)$
+ $d(i)\implies \exists N\in\mathbb{N}(\forall n≥N(P_{ii}^{(nd(i))}>0))$
+ $P_{ji}^{(n)}>0\implies P_{ji}^{(m+nd(i))}>0, \forall n\in\mathbb{N}\text{ sufficiently large}$

A markov chain where all states have period 1 is called **aperiodic**.

## The basic limit theorem
For a recurrent state $i$ define
$$
f_{ii}^{(n)}=Pr\left\{ X_n=i, X_v\neq i \text{ for } v=1,\dots,n-1|X_{0}=i \right\} 
$$
is the probability distribution for the **first return time**
$$
R_i = \min\left\{ n≥1;X_n=i \right\} .
$$
The **mean duration between visits** to state $i$ is
$$
m_i=E[R_i|X_0=i]=\sum_{n=1}^{\infty} nf_{ii}^{(n)}. \, 
$$
>[!info] Theorem 4.3 The basic limit theorem of Markov chains
>*(a)* Consider a recurrent irreducible aperiodic Markov chain. Let $P_{ii}^{(n)}$ be the probability of entering state $i$ at the $n$th transition, $n=0,1,\dots,$ given that $X_0=i$. Define $P_{ii}^{(0)}=1$. Let $f_{ii}^{(n)}$ be the probability of first returning to state $i$ at the $n$th transition, $n=0,1,2,\dots,$ where $f_{ii}^{0}=0$. Then
>$$
>\lim_{ n \to \infty } P_{ii}^{(n)}=\frac{1}{\sum_{n=1}^{\infty} nf_{ii}^{(n)} \, }=\frac{1}{m_i}.
>$$
>
>*(b)* Under the same conditions as in *(a)*, $\lim_{ n \to \infty }P_{ji}^{(n)}=\lim_{ n \to \infty }P_{ii}^{(n)}$ for all states $j$.



