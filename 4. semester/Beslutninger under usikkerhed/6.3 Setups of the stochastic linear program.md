---
Uge: Uge 12
Dato: 23/4/2024
Slides: "[[Uge 12.pdf]]"
---
In the general case, we have
+ $x\in \mathbb{R}^n$, the here-and-now decision variables
+ $y\in \mathbb{R}^l$, the recourse decision variables
+ $\omega$ is the uncertainty parameter

The "basic" program we are interested in is
$$
\begin{align}
\min_x \phi(x,\omega) = c^\top x + \min_y[d^\top y | \to T(\omega)x+Wy = h(\omega), y≥0] \\
s.t. Ax=b
\end{align}
$$
#### 3 different ways to look at how to solve such a program
![[Pasted image 20240423141158.png]]

## Difference from perfect information
How better off would you be knowing perfect information than if using a stochastic linear program

>[!info] The value of the stochastic solution
>The expected result of the expected value solution EEV is defined as
>$$
>EEV = \mathbb{E}_\omega[\phi(x(\bar{\omega}), \omega)],
>$$
>where $x(\bar{\omega})$ is the solution of the EV problem.
>
>The expected value of perfect information $EVPI$ is defined as
>$$
>EVPI = RP-WS.
>$$
>The stochastic solution VSS is defined as
>$$
>VSS = EEV - RP
>$$
>
>**The fundamental ordering**
>$$
>EEV ≥ RP ≥ WS ≥ EV
>$$

>[!example]- Code
>Same example as [6.2](obsidian://open?vault=Noter&file=Beslutninger%20under%20usikkerhed%2F6.2%20Stochastic%20Linear%20Optimization)
>
>```Julia
>#Import necessary Julia packages
>using LinearAlgebra, JuMP, GLPK, Distributions, Random
>
>#Define parameters
>c = 100
>δ = 20
>η = 10
>ns = 5 # number of scenarios
>
>#Obtain scenarios (they are all equiprobable, with probability 1/ns)
>d = Gamma(30,1.5)
>Random.seed!(100) # fix the seed of the random number generator, to be sure we get the same
>ω = rand(d,ns)
>
># Declare vectors to store (here-and-now) decisions and objective function values
>xv = zeros(ns)
>ov = zeros(ns)
>
>for i =1:ns # loop over scenarios
> #Declare model and optimizer
> wsmodel = Model()
> set_optimizer(wsmodel, GLPK.Optimizer)
>
> #Define variables
> @variable(wsmodel, x)
> @variable(wsmodel, y_1)
> @variable(wsmodel, y_2)
> @variable(wsmodel, y_3)
>
> #Define Constraints
> @constraint(wsmodel, - x + y_1 + y_2 == 0)
> @constraint(wsmodel, y_1 + y_3 == ω[i])
> @constraint(wsmodel, y_1 >= 0)
> @constraint(wsmodel, y_2 >= 0)
> @constraint(wsmodel, y_3 >= 0)
> @constraint(wsmodel, x >= 0)
>
> #Define Objective
> @objective(wsmodel, Min, (-c) * x + (c+δ) * y_2 - (c-η) * y_3 )
> #Run the opimization
> optimize!(wsmodel)
>
> #Extract solutions
> xv[i] = value.(x)
> ov[i] = objective_value(wsmodel)
>end
>
>println("WS here-and-now decision: ", mean(xv))
>println("WS = ", mean(ov))
>```

